{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e59481",
   "metadata": {},
   "source": [
    "# Initial Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Scenario\n",
    "With the first batch of data cleaned, your mission is now to conduct an initial Exploratory Data Analysis (EDA). You must develop a reusable, \"data-aware\" analysis function that can generate a standard set of plots for any given dataset. Your goal is to use this function to uncover initial patterns in the data and form a preliminary hypothesis about the UAV's location.\n",
    "\n",
    "## Coding Task Overview\n",
    "- **Import** your `clean_data` function and load the cleaned dataset from Part 2.\n",
    "- **Develop** a new, powerful `perform_eda` function that intelligently checks the data type of each column and generates the appropriate visualization (e.g., histograms for numbers, countplots for categories).\n",
    "- **Apply** this function to the data and write up your findings in an \"Initial Intelligence Report.\"\n",
    "\n",
    "## Mission Deliverable\n",
    "A markdown cell summarizing your initial findings, supported by key plots. This report must include a map that visually identifies a preliminary, high-priority search area based on the strongest signal readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas, numpy, matplotlib.pyplot, seaborn, folium, and plotly.graph_objects\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import os\n",
    "# From our utility file, import the clean_data function\n",
    "from uav_analysis_tools import clean_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c51fa",
   "metadata": {},
   "source": [
    "### STEP 1: Load the Cleaned Data\n",
    "\n",
    "In this part remember that the necessary data files are stored in the ```data``` subdierctory so you will need the ```os``` \n",
    "package's ```os.path.join()``` function to create the proper load location for pandas' CSV reading functions\n",
    "\n",
    "Load the ```cleaned_reports_batch_1.csv``` file into the ```df_clean``` dataframe using pandas ```read_csv()``` function on the correct filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = None #placeholder for the data directory\n",
    "datafilepath = None #placeholder for the data file path\n",
    "\n",
    "df_clean = None #placeholder for the cleaned dataframe\n",
    "\n",
    "##########################################################\n",
    "##### START STUDENT CODE HERE:\n",
    "\n",
    "#Set the DATA_DIR variable to 'data'\n",
    "DATA_DIR = None # placeholder\n",
    "\n",
    "#create the datafilepath variable by joining DATA_DIR and 'cleaned_reports_batch_1.csv' using os.path.join()\n",
    "datafilepath = None # placeholder\n",
    "\n",
    "# Load the csv file into a DataFrame called df_clean using pd.read_csv()\n",
    "df_clean = None # placeholder\n",
    "\n",
    "\n",
    "##### END STUDENT CODE HERE\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "# Display the first few rows with .head() to confirm it loaded correctly.\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b8f05",
   "metadata": {},
   "source": [
    "### STEP 2: Generate the Interactive Map of Team Reports\n",
    "\n",
    "No Student Coding Required\n",
    "\n",
    "Since the teams conducted operations in a specific geographic area, a first step of Exploratory Data Analysis (EDA) is to map their locations and information from their report.\n",
    "\n",
    "This step will create a map of the locations of the team reports where each team's received signal strength is shown on a color range from blue (low or no signal received) to yellow (high signal strength).   The report location markers can be clicked on for more info about the report.\n",
    "\n",
    "The mapping function ```EDA_makeMap``` is present in the ```uav_mapping_tools.py``` python file and is imported before being used here.  The map can be panned and zoomed, and the map type can be selected using the layer GUI icon in the upper right to select between topographic map, street map, or satellite view\n",
    "\n",
    "Note that some notebooks may experience a \"Notebook not trusted\" error and not allow the map to be shown.  If this happens, the user can try closing and reopening the notebook or clicking on the button \"Not Trusted\" in the jupyter web application when displaying the notebook. \n",
    "\n",
    "Additionally, some visual glitches may occur such as portions of the map not appearing to load - this is typically due to issues with the user's bandwidth or availability of the map server.  These glitches may become more apparent if the user tries to zoom out or pan the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a20f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the map.  Sometimes the map may not be visible.  Solutions include:\n",
    "# 1) close and reopen the notebook\n",
    "# 2) restart the kernel and run all cells again\n",
    "# 3) Ensure the notebook is trusted (in Jupyter, go to File -> Trust Notebook)\n",
    "import uav_mapping_tools\n",
    "m = uav_mapping_tools.EDA_makeMap(df_clean, force_regenerate=True)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b323b",
   "metadata": {},
   "source": [
    "### STEP 3: Perform the Exploratory Data Analysis (EDA) Visualizations\n",
    "\n",
    "STUDENT CODE REQUIRED\n",
    "\n",
    "There are three locations for the student code\n",
    "1. a barplot of the number of reports which came in during each of the 24 hours of the day\n",
    "1. a barplot of the number of reports which came in per team\n",
    "1. a scatterplot of the sorted values of the signal strength of the reports\n",
    "\n",
    "Once this function is written and working properly, add the ```perform_eda``` function to the ```uav_analysis_tools.py``` file and save the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc35e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Perform the Exploratory Data Analysis (EDA) Visualizations\n",
    "def perform_eda(df, target_column):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    # 1. Print the DataFrame's .info() and .describe() summaries.\n",
    "    print(\"DataFrame Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nDataFrame Description:\")\n",
    "    print(df.describe(include='all'))\n",
    "\n",
    "    # 2. Separate the feature columns from the target column.\n",
    "    features = df.drop(columns=[target_column])\n",
    "    target = df[target_column]\n",
    "\n",
    "    # 3. Loop through each feature column and plot the appropriate visualizations.:\n",
    "    for column in features.columns:\n",
    "        print(\"Handling column\",column)\n",
    "        if column == 'timestamp':\n",
    "            # Special handling for timestamp: plot count by hour of day\n",
    "\n",
    "            \n",
    "            features['timestamp'] = pd.to_datetime(features['timestamp'], errors='coerce')\n",
    "            features['hour'] = features['timestamp'].dt.hour\n",
    "\n",
    "            hour_counts = features['hour'].value_counts().sort_index()\n",
    "            hour_count_index = hour_counts.index  #get the index of the hour for the horizontal axis labels\n",
    "            hour_count_values = hour_counts.values #get the counts of the hours for the vertical axis values\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "\n",
    "            # now plot the bar chart of how many reports came in for each hour of the day\n",
    "            # use hour_count_index for the x values and hour_count_values for the y values\n",
    "\n",
    "            ##########################################################\n",
    "            ##### START STUDENT CODE HERE:\n",
    "\n",
    "            # use sns.barplot() to create the bar chart\n",
    "            \n",
    "\n",
    "\n",
    "            ##### END STUDENT CODE HERE\n",
    "            ##########################################################\n",
    "\n",
    "            plt.title('Report Counts by Hour of Day')\n",
    "            plt.xlabel('Hour of Day')\n",
    "            plt.ylabel('Number of Reports')\n",
    "            plt.show()\n",
    "\n",
    "        if column == 'team_callsign':\n",
    "            # Special handling for team_callsign: plot top N most common callsigns\n",
    "\n",
    "            top_callsigns = features[column].value_counts().head(10)\n",
    "            \n",
    "            top_callsigns_index = top_callsigns.index  #get the index of the hour for the horizontal axis labels\n",
    "            top_callsigns_values = top_callsigns.values #get the counts of the hours for the vertical axis values\n",
    "\n",
    "\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.title('Top 10 Team Callsigns by Report Count')\n",
    "            plt.xlabel('Team Callsign')\n",
    "            plt.ylabel('Number of Reports')            \n",
    "            plt.xticks(rotation=45)            \n",
    "\n",
    "            # now plot the bar chart of how many reports came in for each of the top 10 team callsigns      \n",
    "            # use top_callsigns_index for the x values and top_callsigns_values for the y values\n",
    "            \n",
    "            ##########################################################\n",
    "            ##### START STUDENT CODE HERE:\n",
    "\n",
    "            # use sns.barplot() to create the bar chart\n",
    "            \n",
    "\n",
    "            ##### END STUDENT CODE HERE\n",
    "            ##########################################################\n",
    "            plt.show()\n",
    "\n",
    "            continue\n",
    "        if column == 'report_id':\n",
    "            # Skip histogram and scatterplot for report_id as it's not useful\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # a. Check the column's data type (dtype).\n",
    "        if hasattr(features[column], 'dtype') and hasattr(features[column], 'values') and hasattr(features[column], 'name'):\n",
    "            if hasattr(features[column], 'dtype') and hasattr(features[column].dtype, 'kind') and features[column].dtype.kind in 'ifc':\n",
    "                # Numeric\n",
    "                plt.subplot(1, 2, 1)\n",
    "                sns.histplot(features[column], bins=20, kde=False)\n",
    "                plt.title(f'Histogram of {column}')\n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                sns.scatterplot(x=features[column], y=target)\n",
    "                plt.title(f'Scatter plot of {column} vs {target_column}')\n",
    "\n",
    "            elif hasattr(features[column], 'dtype') and (features[column].dtype.name == 'category' or features[column].dtype == object):\n",
    "                # Categorical\n",
    "                plt.subplot(1, 2, 1)\n",
    "                sns.countplot(y=features[column])\n",
    "                plt.title(f'Countplot of {column}')\n",
    "\n",
    "                if hasattr(target, 'dtype') and hasattr(target.dtype, 'kind') and target.dtype.kind in 'ifc':\n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    sns.boxplot(x=features[column], y=target)\n",
    "                    plt.title(f'Box plot of {column} vs {target_column}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 4. After the loop, create a correlation heatmap for all numeric columns in the DataFrame.\n",
    "    numeric_cols = df.select_dtypes(include=['number'])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(numeric_cols.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap')\n",
    "\n",
    "    # 5. Sorted scatterplot of signal strength\n",
    "    if 'signal_strength' in df.columns:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sorted_signal = df['signal_strength'].sort_values().reset_index(drop=True)\n",
    "\n",
    "        signal_strength_index = sorted_signal.index  #get the index of the hour for the horizontal axis labels\n",
    "        signal_strength_values = sorted_signal.values #get the counts of the hours for the vertical axis values\n",
    "\n",
    "        plt.title('Sorted Scatterplot of Signal Strength')\n",
    "        plt.xlabel('Sorted Index')\n",
    "        plt.ylabel('Signal Strength')\n",
    "\n",
    "\n",
    "        # now plot the scatterplot of the sorted signal strength values using plt.scatter()\n",
    "        # use signal_strength_index for the x values and signal_strength_values for the y values\n",
    "        # and set the alpha to 0.7 for better visibility\n",
    "\n",
    "        ##########################################################\n",
    "        ##### START STUDENT CODE HERE:\n",
    "\n",
    "        # use plt.scatter() to create the scatter plot\n",
    "        \n",
    "\n",
    "        ##### END STUDENT CODE HERE\n",
    "        ##########################################################\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply your new perform_eda function to the df_clean DataFrame.\n",
    "# The target column is 'signal_strength'.\n",
    "perform_eda(df_clean, 'signal_strength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced6c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
