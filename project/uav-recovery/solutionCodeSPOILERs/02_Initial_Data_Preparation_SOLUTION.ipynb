{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Data Cleaning and Preprocessing\n",
    "\n",
    "**Scenario:** The first batch of real-time data has arrived from the field. Intelligence reports that a solar storm occurred between 08:00 and 09:30 Zulu, potentially corrupting any data transmitted during that window. Your first task is to isolate and remove these untrustworthy reports. After that, you must develop a robust, reusable Python function to clean the remaining messy data.\n",
    "\n",
    "**Coding Task Overview:** You will load the messy data, convert the timestamp column to a datetime format, and then filter out the unreliable rows from the solar storm period. You will then develop a `clean_data` function to handle various errors like missing values, incorrect data types, and typos. Finally, you will save both your cleaned data to a new CSV and your reusable function to an external Python utility file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Load and Inspect the Raw Data\n",
    "\n",
    "STUDENT CODE REQUIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   report_id              200 non-null    int64  \n",
      " 1   timestamp              200 non-null    object \n",
      " 2   team_callsign          200 non-null    object \n",
      " 3   latitude               200 non-null    float64\n",
      " 4   longitude              200 non-null    float64\n",
      " 5   elevation_m            200 non-null    float64\n",
      " 6   wind_direction_deg     198 non-null    object \n",
      " 7   ambient_temp_c         200 non-null    float64\n",
      " 8   battery_level_percent  190 non-null    float64\n",
      " 9   signal_strength        37 non-null     object \n",
      "dtypes: float64(5), int64(1), object(4)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the field_reports_batch_1.csv file into a DataFrame called df_raw.\n",
    "# Display the .info() summary to show the initial messy state and wrong data types.\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "datafilepath = os.path.join(DATA_DIR, 'field_reports_batch_1.csv')\n",
    "\n",
    "##########################################################\n",
    "##### START STUDENT CODE HERE:\n",
    "\n",
    "df_raw = pd.read_csv(datafilepath)\n",
    "df_raw.info()\n",
    "\n",
    "##### END STUDENT CODE HERE\n",
    "##########################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Perform Initial Diagnosis on Unclean Data\n",
    "\n",
    "STUDENT CODE REQUIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team_callsign\n",
       "Alpha      10\n",
       "alfa        8\n",
       "bravo       6\n",
       "TEAM001     1\n",
       "TEAM137     1\n",
       "           ..\n",
       "TEAM070     1\n",
       "TEAM071     1\n",
       "TEAM073     1\n",
       "TEAM074     1\n",
       "TEAM200     1\n",
       "Name: count, Length: 179, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a count of the different callsigns to see the typos using .value_counts() on the team_callsign column.\n",
    "\n",
    "##########################################################\n",
    "##### START STUDENT CODE HERE:\n",
    "\n",
    "df_raw['team_callsign'].value_counts(dropna=False)\n",
    "\n",
    "##### END STUDENT CODE HERE\n",
    "##########################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Remove Corrupted Data from the Solar Storm Period\n",
    "\n",
    "STUDENT CODE REQUIRED\n",
    "\n",
    "To eliminate portions of corrupted data, use ```Pandas``` filtering commands to remove a section of time corresponding to the solar storm.\n",
    "In ```Pandas```, selecting rows *other than* a certain set can be accomplished using a combination of   ```~``` and\n",
    "boolean logic operators such as ```&``` using careful placement of parentheses to control the order of operations\n",
    "\n",
    "Additionally, the ```pandas``` operation ```.copy``` will return a copy of the datafram instead of altering the original\n",
    "\n",
    "Use ```pd.Timestamp``` to create filtering timestamps to exclude the solar storm period.  Timestamps are in the format ```'YYYY-MM-DD HH:MM:SS'```\n",
    "\n",
    "* use ```storm_start``` as ```'2025-08-21 08:00:00'```\n",
    "* and ```storm_end``` as ```'2025-08-21 09:30:00'```\n",
    "\n",
    "the original dataframe is ```df_raw``` and this code cell should create a filtered dataframe called ```df_filtered``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before filtering: 200 (should be 200)\n",
      "Rows after filtering: 190 (should be 190)\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'timestamp' column to a proper datetime object.\n",
    "df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'], errors='coerce')\n",
    "before_rows = len(df_raw)\n",
    "\n",
    "df_filtered = None  #placeholder for the filtered dataframe\n",
    "\n",
    "##########################################################\n",
    "##### START STUDENT CODE HERE:\n",
    "\n",
    "\n",
    "# define the period of the solar storm to be exculded by defining the pd.Timestamp for storm_start and storm_end\n",
    "# the form of a timestamp is pd.Timestamp('YYYY-MM-DD HH:MM:SS')\n",
    "storm_start = pd.Timestamp('2025-08-21 08:00:00')\n",
    "storm_end = pd.Timestamp('2025-08-21 09:30:00')\n",
    "\n",
    "# Create a copy of a filtered DataFrame that excludes rows during the solar storm period \n",
    "# using boolean logic on the timestamps with ~ to exclude a selection and inequality operators such as >=  and <= along with & for boolean AND\n",
    "# make sure to copy the dataframe int df_filtered instead of altering df_raw\n",
    "df_filtered = df_raw[~((df_raw['timestamp'] >= storm_start) & (df_raw['timestamp'] <= storm_end))].copy()\n",
    "\n",
    "##### END STUDENT CODE HERE\n",
    "##########################################################\n",
    "\n",
    "\n",
    "after_rows = len(df_filtered)\n",
    "print(f\"Rows before filtering: {before_rows} (should be 200)\")\n",
    "print(f\"Rows after filtering: {after_rows} (should be 190)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: Define the Reusable Cleaning Function\n",
    "\n",
    "STUDENT CODE REQUIRED\n",
    "\n",
    "Note:  After you run this cell during Step 5 and confirm it works properly in Step 6, the function you write here should be copied in the python file for utilities which can be imported later.  This file is called ```uav_analysis_tools.py``` and the importable function should be called ```clean_data```.  Don't change other parts of the ```uav_analysis_tools.py``` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the clean_data function\n",
    "\n",
    "def clean_data(df, noise_floor=-120):\n",
    "    \"\"\"\n",
    "    Cleans the UAV field report DataFrame.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1.  Standardizes missing value placeholders ('?', 'N/A', '') to np.nan.\n",
    "    2.  Standardizes 'team_callsign' to lowercase, corrects known typos,\n",
    "        and fills any missing callsigns with 'unknown'.\n",
    "    3.  For the 'signal_strength' column, converts it to numeric (coercing errors)\n",
    "        and imputes missing values (NaNs) with the specified noise_floor.\n",
    "    4.  For all other numeric columns, converts them to numeric (coercing errors)\n",
    "        and imputes missing values with the column's median.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The raw field report DataFrame.\n",
    "        noise_floor (int or float, optional): The noise floor (in dBm) to use for\n",
    "            imputing missing signal strength values. Defaults to -120.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_clean = df.copy()   \n",
    "\n",
    "    ##########################################################\n",
    "    ##### START STUDENT CODE HERE:\n",
    "\n",
    "    # 1. Standardize missing values across the entire DataFrame using .replace()  you should covert all instances of  ['?', 'N/A', ''] to np.nan.\n",
    "    df_clean.replace(['?', 'N/A', ''], np.nan, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    # 2. Handle categorical typos (team_callsign)\n",
    "    if 'team_callsign' in df_clean.columns:\n",
    "        \n",
    "        # Fill missing values, standardize casing and strip whitespace using .fillna(), .str.lower(), and .str.strip()\n",
    "        # Chain string operations for efficiency and clarity\n",
    "        df_clean['team_callsign'] = df_clean['team_callsign'].fillna('unknown').str.lower().str.strip()\n",
    "\n",
    "        # Correct known typos such as 'alfa' to 'alpha' by using a map of {`from`: `to`} and the .replace() method\n",
    "        typo_map = {'alfa': 'alpha'}\n",
    "        df_clean['team_callsign'] = df_clean['team_callsign'].replace(typo_map)\n",
    "\n",
    "\n",
    "    # 3. Special handling for signal_strength imputation\n",
    "    if 'signal_strength' in df_clean.columns:\n",
    "\n",
    "        # Convert to numeric, coercing errors (like 'ERR-&^%') to NaN by using pd.to_numeric() and the errors='coerce' parameter\n",
    "        df_clean['signal_strength'] = pd.to_numeric(df_clean['signal_strength'], errors='coerce')\n",
    "\n",
    "        # Impute NaN values with the noise_floor by using the dataframe .fillna() method, passing in the noise_floor parameter \n",
    "        df_clean['signal_strength'] = df_clean['signal_strength'].fillna(noise_floor)\n",
    "\n",
    "\n",
    "\n",
    "    # 4. Identify and impute other numeric columns with their median\n",
    "    # Exclude columns we've already handled or know are non-numeric using the dataframe .columns.drop() method and the errors='ignore' parameter\n",
    "    numeric_cols = df_clean.columns.drop(['timestamp', 'team_callsign', 'report_id', 'signal_strength'], errors='ignore')\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        # Convert to numeric, coercing errors to NaN using the pd.to_numeric() function with the errors='coerce' parameter\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "        # Calculate the median of the now-numeric column using the dataframe .median() method\n",
    "        median_val = df_clean[col].median()\n",
    "        # Fill any NaNs (original or coerced) with the median using the dataframe .fillna() method with inplace=True\n",
    "        df_clean[col] = df_clean[col].fillna(median_val)\n",
    "\n",
    "\n",
    "\n",
    "    ##### END STUDENT CODE HERE\n",
    "    ##########################################################\n",
    "    \n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: Apply the Cleaning Function\n",
    "\n",
    "STUDENT CODE REQUIRED\n",
    "\n",
    "Special Note - after confirming the code you wrote for the clean_data() function works properly when it is called from this cell and gives the correct results in step 6, copy the function contents (from the signature line beginning with ```def``` all the way to the end of the ```return``` line) into the ```uav_analysis_tools.py``` file.  Don't change other parts of the ```uav_analysis_tools.py``` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 190 entries, 0 to 199\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   report_id              190 non-null    int64         \n",
      " 1   timestamp              190 non-null    datetime64[ns]\n",
      " 2   team_callsign          190 non-null    object        \n",
      " 3   latitude               190 non-null    float64       \n",
      " 4   longitude              190 non-null    float64       \n",
      " 5   elevation_m            190 non-null    float64       \n",
      " 6   wind_direction_deg     190 non-null    float64       \n",
      " 7   ambient_temp_c         190 non-null    float64       \n",
      " 8   battery_level_percent  190 non-null    float64       \n",
      " 9   signal_strength        190 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int64(1), object(1)\n",
      "memory usage: 16.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#from uav_analysis_tools import clean_data\n",
    "\n",
    "# Apply the clean_data function to the df_filtered DataFrame.\n",
    "# Store the result in df_clean and display the .info() summary.\n",
    "\n",
    "df_clean = None #placeholder for cleaned dataframe\n",
    "\n",
    "##########################################################\n",
    "##### START STUDENT CODE HERE:\n",
    "\n",
    "df_clean = clean_data(df_filtered)\n",
    "\n",
    "##### END STUDENT CODE HERE\n",
    "##########################################################\n",
    "\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: Verify the Cleaning Results\n",
    "\n",
    "You should review the code and ensure that after running it on your ```df_clean``` dataframe, all tests are successful.  If any warnings appear it may be the case that the data was not cleaned properly\n",
    "\n",
    "Special Note - after confirming the code you wrote for the clean_data() function you wrote in Step 4 works properly when it is called from this cell, copy the function contents (from the signature line beginning with ```def``` all the way to the end of the ```return``` line) into the ```uav_analysis_tools.py``` file where indicated.  Don't change other parts of the ```uav_analysis_tools.py``` file\n",
    "\n",
    "No Student Code Required for this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verification of Numeric Data ---\n",
      "This summary should show a count of 190 for all columns, with no NaNs or extreme outliers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>wind_direction_deg</th>\n",
       "      <th>ambient_temp_c</th>\n",
       "      <th>battery_level_percent</th>\n",
       "      <th>signal_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>104.868421</td>\n",
       "      <td>37.344640</td>\n",
       "      <td>-119.097200</td>\n",
       "      <td>2544.412640</td>\n",
       "      <td>174.784290</td>\n",
       "      <td>24.909122</td>\n",
       "      <td>59.987464</td>\n",
       "      <td>-119.127373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>56.063631</td>\n",
       "      <td>0.142428</td>\n",
       "      <td>0.168081</td>\n",
       "      <td>630.491722</td>\n",
       "      <td>97.744053</td>\n",
       "      <td>4.965662</td>\n",
       "      <td>23.118881</td>\n",
       "      <td>2.484629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.100522</td>\n",
       "      <td>-119.399287</td>\n",
       "      <td>830.012817</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>12.990374</td>\n",
       "      <td>20.054683</td>\n",
       "      <td>-120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.250000</td>\n",
       "      <td>37.229791</td>\n",
       "      <td>-119.232820</td>\n",
       "      <td>2177.350403</td>\n",
       "      <td>95.448285</td>\n",
       "      <td>21.586530</td>\n",
       "      <td>41.445158</td>\n",
       "      <td>-120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>105.500000</td>\n",
       "      <td>37.342196</td>\n",
       "      <td>-119.099862</td>\n",
       "      <td>2611.797974</td>\n",
       "      <td>172.333224</td>\n",
       "      <td>24.776327</td>\n",
       "      <td>59.759282</td>\n",
       "      <td>-120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>152.750000</td>\n",
       "      <td>37.460531</td>\n",
       "      <td>-118.958693</td>\n",
       "      <td>2986.838806</td>\n",
       "      <td>258.311969</td>\n",
       "      <td>28.422566</td>\n",
       "      <td>78.447631</td>\n",
       "      <td>-120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>37.598934</td>\n",
       "      <td>-118.801411</td>\n",
       "      <td>3883.077637</td>\n",
       "      <td>350.733465</td>\n",
       "      <td>39.421910</td>\n",
       "      <td>99.927824</td>\n",
       "      <td>-106.447427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        report_id    latitude   longitude  elevation_m  wind_direction_deg  \\\n",
       "count  190.000000  190.000000  190.000000   190.000000          190.000000   \n",
       "mean   104.868421   37.344640 -119.097200  2544.412640          174.784290   \n",
       "std     56.063631    0.142428    0.168081   630.491722           97.744053   \n",
       "min      1.000000   37.100522 -119.399287   830.012817            0.013178   \n",
       "25%     58.250000   37.229791 -119.232820  2177.350403           95.448285   \n",
       "50%    105.500000   37.342196 -119.099862  2611.797974          172.333224   \n",
       "75%    152.750000   37.460531 -118.958693  2986.838806          258.311969   \n",
       "max    200.000000   37.598934 -118.801411  3883.077637          350.733465   \n",
       "\n",
       "       ambient_temp_c  battery_level_percent  signal_strength  \n",
       "count      190.000000             190.000000       190.000000  \n",
       "mean        24.909122              59.987464      -119.127373  \n",
       "std          4.965662              23.118881         2.484629  \n",
       "min         12.990374              20.054683      -120.000000  \n",
       "25%         21.586530              41.445158      -120.000000  \n",
       "50%         24.776327              59.759282      -120.000000  \n",
       "75%         28.422566              78.447631      -120.000000  \n",
       "max         39.421910              99.927824      -106.447427  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All latitude entries are within the valid range (-90 to 90).\n",
      "All longitude entries are within the valid range (-180 to 180).\n",
      "All wind_direction_deg entries are within the valid range (0-360).\n",
      "All battery_level_percent entries are within the valid range (0-100%).\n",
      "All signal_strength entries are above the noise floor (-120 dBm).\n",
      "\n",
      "\n",
      "\n",
      "--- Verification of Categorical Data ---\n",
      "This summary should show standardized, lowercase callsigns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_callsign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_callsign\n",
       "count            190\n",
       "unique           168\n",
       "top            alpha\n",
       "freq              18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most common team_callsign values:\n",
      "team_callsign\n",
      "alpha      18\n",
      "bravo       6\n",
      "team129     1\n",
      "team131     1\n",
      "team132     1\n",
      "team133     1\n",
      "team134     1\n",
      "team135     1\n",
      "team137     1\n",
      "team138     1\n",
      "Name: count, dtype: int64\n",
      "Number of unique team_callsign entries: 168\n",
      "All team_callsign entries are properly formatted.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Separate columns by their data type\n",
    "numeric_cols = df_clean.select_dtypes(include=np.number)\n",
    "categorical_cols = df_clean.select_dtypes(include='object')\n",
    "\n",
    "# 2. Verify the numeric columns\n",
    "print(\"--- Verification of Numeric Data ---\")\n",
    "print(\"This summary should show a count of 190 for all columns, with no NaNs or extreme outliers.\")\n",
    "display(numeric_cols.describe())\n",
    "\n",
    "\n",
    "#verify that the meaningful numeric columns contain reasonable values\n",
    "\n",
    "#verify that latitude is between -90 and 90 and that longitude is between -180 and 180\n",
    "if 'latitude' in numeric_cols.columns:\n",
    "    if ((numeric_cols['latitude'] < -90) | (numeric_cols['latitude'] > 90)).any():\n",
    "        print(\"Warning: Some latitude entries are out of the valid range (-90 to 90).\")\n",
    "    else:\n",
    "        print(\"All latitude entries are within the valid range (-90 to 90).\")  \n",
    "if 'longitude' in numeric_cols.columns:\n",
    "    if ((numeric_cols['longitude'] < -180) | (numeric_cols['longitude'] > 180)).any():\n",
    "        print(\"Warning: Some longitude entries are out of the valid range (-180 to 180).\")\n",
    "    else:\n",
    "        print(\"All longitude entries are within the valid range (-180 to 180).\")    \n",
    "\n",
    "#verify that wind direction is between 0 and 360\n",
    "if 'wind_direction_deg' in numeric_cols.columns:\n",
    "    if ((numeric_cols['wind_direction_deg'] < 0) | (numeric_cols['wind_direction_deg'] > 360)).any():\n",
    "        print(\"Warning: Some wind_direction_deg entries are out of the valid range (0-360).\")\n",
    "    else:\n",
    "        print(\"All wind_direction_deg entries are within the valid range (0-360).\")\n",
    "\n",
    "#verify that ambient_temperature is within a reasonable range in celcius\n",
    "if 'ambient_temperature' in numeric_cols.columns:\n",
    "    if ((numeric_cols['ambient_temperature'] < -50) | (numeric_cols['ambient_temperature'] > 60)).any():\n",
    "        print(\"Warning: Some ambient_temperature entries are outside the reasonable range (-50 to 60 °C).\")\n",
    "    else:\n",
    "        print(\"All ambient_temperature entries are within the reasonable range (-50 to 60 °C).\")\n",
    "\n",
    "#verify that battery_level_percent is between 0 and 100%\n",
    "if 'battery_level_percent' in numeric_cols.columns:\n",
    "    if ((numeric_cols['battery_level_percent'] < 0) | (numeric_cols['battery_level_percent'] > 100)).any():\n",
    "        print(\"Warning: Some battery_level_percent entries are out of the valid range (0-100%).\")\n",
    "    else:\n",
    "        print(\"All battery_level_percent entries are within the valid range (0-100%).\")\n",
    "\n",
    "#verify that signal_strength has no values below the noise floor\n",
    "if 'signal_strength' in numeric_cols.columns:\n",
    "    if (numeric_cols['signal_strength'] < -120).any():\n",
    "        print(\"Warning: Some signal_strength entries are below the noise floor (-120 dBm).\")\n",
    "    else:\n",
    "        print(\"All signal_strength entries are above the noise floor (-120 dBm).\")  \n",
    "\n",
    "print(\"\\n\" * 2) # Add space for readability\n",
    "\n",
    "# 3. Verify the categorical columns\n",
    "print(\"--- Verification of Categorical Data ---\")\n",
    "print(\"This summary should show standardized, lowercase callsigns.\")\n",
    "display(categorical_cols.describe())\n",
    "#show the top 10 most common callsigns to verify no typos\n",
    "if 'team_callsign' in categorical_cols.columns:\n",
    "    print(\"\\nTop 10 most common team_callsign values:\")\n",
    "    print(categorical_cols['team_callsign'].value_counts().head(10))    \n",
    "\n",
    "# 4. Additional checks for specific columns\n",
    "# check that all team_callsign values are in lowercase and contain no leading/trailing whitespace\n",
    "if 'team_callsign' in categorical_cols.columns:\n",
    "    callsign_issues = categorical_cols['team_callsign'].apply(lambda x: x != x.strip() or not x.islower())\n",
    "    if callsign_issues.any():\n",
    "        print(\"Warning: Some team_callsign entries have casing or whitespace issues.\")\n",
    "    else:\n",
    "        #count the number of unique callsigns\n",
    "        unique_callsigns = categorical_cols['team_callsign'].nunique()\n",
    "        print(f\"Number of unique team_callsign entries: {unique_callsigns}\")\n",
    "        print(\"All team_callsign entries are properly formatted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7: Save the Final Cleaned Dataset\n",
    "\n",
    "No student code required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'data\\cleaned_reports_batch_1.csv' has been saved.\n"
     ]
    }
   ],
   "source": [
    "# Save df_clean to a new CSV file named cleaned_reports_batch_1.csv in the data subdierctory.\n",
    "# Do not include the pandas index in the saved file.\n",
    "# Print a confirmation message.\n",
    "output_path = os.path.join(DATA_DIR, 'cleaned_reports_batch_1.csv')\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\"File '{output_path}' has been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
